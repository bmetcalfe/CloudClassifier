{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Optimizer\n",
    "import keras\n",
    "\n",
    "import cv2\n",
    "import albumentations\n",
    "import segmentation_models as sm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Label</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0011165.jpg_Fish</td>\n",
       "      <td>264918 937 266318 937 267718 937 269118 937 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0011165.jpg_Flower</td>\n",
       "      <td>1355565 1002 1356965 1002 1358365 1002 1359765...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0011165.jpg_Gravel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0011165.jpg_Sugar</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>002be4f.jpg_Fish</td>\n",
       "      <td>233813 878 235213 878 236613 878 238010 881 23...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image_Label                                      EncodedPixels\n",
       "0    0011165.jpg_Fish  264918 937 266318 937 267718 937 269118 937 27...\n",
       "1  0011165.jpg_Flower  1355565 1002 1356965 1002 1358365 1002 1359765...\n",
       "2  0011165.jpg_Gravel                                                NaN\n",
       "3   0011165.jpg_Sugar                                                NaN\n",
       "4    002be4f.jpg_Fish  233813 878 235213 878 236613 878 238010 881 23..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../Capstone/understanding_cloud_organization/'\n",
    "train_df = pd.read_csv(path + 'train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['image'] = train_df['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "train_df['class'] = train_df['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "train_df['masked'] = ~ train_df['EncodedPixels'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['fish','sugar','gravel','flower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fish'] = np.where((train_df['class']=='Fish') & (train_df['masked'] == True),1,0)\n",
    "train_df['sugar'] = np.where((train_df['class']=='Sugar') & (train_df['masked'] == True),1,0)\n",
    "train_df['gravel'] = np.where((train_df['class']=='Gravel') & (train_df['masked'] == True),1,0)\n",
    "train_df['flower'] = np.where((train_df['class']=='Flower') & (train_df['masked'] == True),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_df = train_df.groupby('image').agg(np.sum).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Length Encoder to convert the Encoded Pixel column in to an actual coverage mask.\n",
    "#Also the \"deconverter\" to convert it back in to a column of encoded pixels \n",
    "#in order to conform to the submission guidlines.\n",
    "#Citation and links in the Run Length Encoder Notebook.\n",
    "\n",
    "def rle_to_mask(rle_string, height, width):\n",
    "    '''\n",
    "    convert RLE(run length encoding) string to numpy array\n",
    "\n",
    "    Parameters: \n",
    "    rle_string (str): string of rle encoded mask\n",
    "    height (int): height of the mask\n",
    "    width (int): width of the mask \n",
    "\n",
    "    Returns: \n",
    "    numpy.array: numpy array of the mask\n",
    "    '''\n",
    "    \n",
    "    rows, cols = height, width\n",
    "    \n",
    "    if rle_string == -1:\n",
    "        return np.zeros((height, width))\n",
    "    else:\n",
    "        rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n",
    "        #print(rle_numbers)\n",
    "        rle_pairs = np.array(rle_numbers).reshape(-1,2)\n",
    "        #print(rle_pairs)\n",
    "        img = np.zeros(rows*cols, dtype=np.uint8)\n",
    "        #print(img)\n",
    "        for index, length in rle_pairs:\n",
    "            index -= 1\n",
    "            img[index:index+length] = 255\n",
    "        img = img.reshape(cols,rows)\n",
    "        img = img.T\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_img, val_img = train_test_split( mask_df.index, random_state=42, test_size=0.2)\n",
    "\n",
    "tr_gen = ImageDataGenerator(tr_img, df=mask_df, target_df=train_df, batch_size=16,\n",
    "                                reshape=(320, 480), augment=True, n_channels=3, n_classes=4)\n",
    "\n",
    "val_gen = ImageDataGenerator(val_img, df=mask_df, target_df=train_df, batch_size=16, \n",
    "                                reshape=(320, 480), augment=False, n_channels=3, n_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7e209a672051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = sm.Unet(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m'resnet34'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sm' is not defined"
     ]
    }
   ],
   "source": [
    "model = sm.Unet('resnet34', classes=4, input_shape=(320, 480, 3), activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Nadam(lr=0.0002), loss=bce_dice_loss, metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Checkpoints in case of crash... and only save the best performing model.\n",
    "checkpoint = ModelCheckpoint('model.h5', save_best_only=True)\n",
    "\n",
    "history = model.fit_generator(tr_gen, validation_data=val_gen, callbacks=[checkpoint], epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(path + '/sample_submission.csv')\n",
    "sub_df['ImageId'] = sub_df['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "test = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building lists of image ids to make batches.  Then feed in to imageDataGenerator to make the batches for prediction.\n",
    "for i in range(0, test.shape[0], 500):\n",
    "    batch = list(range(i, min(test_imgs.shape[0], i + 500)))\n",
    "    \n",
    "test_gen = ImageDataGenerator(batch, df=test_imgs, shuffle=False, mode='predict', dim=(350, 525),\n",
    "                                    reshape=(320, 480), n_channels=3, base_path= (path + '/test_images'), \n",
    "                                    target_df=sub_df, batch_size=1, n_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(columns='ImageId', inplace=True)\n",
    "test_df.to_csv('sub_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
